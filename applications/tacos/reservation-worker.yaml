apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: reservation-worker
  namespace: argocd
  labels:
    app.kubernetes.io/name: reservation-worker
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: background-worker
    app.kubernetes.io/managed-by: argocd
    tier: worker
    service-type: background-job
    scaling-type: event-driven
    platform: traffic-tacos
    cost-center: engineering
    team: backend-team
  annotations:
    argocd.argoproj.io/sync-wave: "30"  # Deploy after APIs
    notifications.argoproj.io/subscribe.on-sync-succeeded.slack: traffic-tacos-deployments
    notifications.argoproj.io/subscribe.on-health-degraded.pagerduty: reservation-worker-alerts
    link.argocd.argoproj.io/external-link: https://grafana.traffictacos.com/d/reservation-worker/reservation-worker-dashboard
    keda.sh/scaling-enabled: "true"
    performance.traffictacos.com/scale-to-zero: "true"
    performance.traffictacos.com/max-replicas: "100"
spec:
  project: traffic-tacos

  # Source configuration
  source:
    repoURL: https://github.com/traffic-tacos/reservation-worker
    targetRevision: main
    path: k8s/manifests

    # Helm configuration for KEDA-enabled background worker
    helm:
      valueFiles:
        - values-prod.yaml
      parameters:
        - name: image.tag
          value: "latest"
        - name: image.repository
          value: "traffic-tacos/reservation-worker"

        # Resource allocation for event-driven worker
        - name: resources.requests.cpu
          value: "200m"
        - name: resources.requests.memory
          value: "256Mi"
        - name: resources.limits.cpu
          value: "1000m"
        - name: resources.limits.memory
          value: "1Gi"

        # KEDA scaling configuration
        - name: keda.enabled
          value: "true"
        - name: keda.minReplicas
          value: "0"  # Scale to zero when no messages
        - name: keda.maxReplicas
          value: "100"  # Handle high message volumes
        - name: keda.pollingInterval
          value: "30"  # Check queue every 30 seconds
        - name: keda.cooldownPeriod
          value: "300"  # 5 minutes cooldown

        # SQS configuration for KEDA scaler
        - name: sqs.queueName
          value: "traffic-tacos-reservation-events"
        - name: sqs.region
          value: "ap-northeast-2"
        - name: sqs.targetQueueLength
          value: "5"  # 1 pod per 5 messages

        # AWS configuration
        - name: aws.region
          value: "ap-northeast-2"
        - name: aws.roleArn
          value: "arn:aws:iam::ACCOUNT-ID:role/traffic-tacos-reservation-worker-role"

        # Job processing configuration
        - name: worker.batchSize
          value: "10"  # Process 10 messages per batch
        - name: worker.maxRetries
          value: "3"
        - name: worker.processingTimeout
          value: "300s"  # 5 minutes per batch

        # Observability
        - name: serviceMonitor.enabled
          value: "true"
        - name: tracing.enabled
          value: "true"

        # Security
        - name: securityContext.runAsNonRoot
          value: "true"
        - name: securityContext.runAsUser
          value: "1000"

  # Destination configuration
  destination:
    server: https://kubernetes.default.svc
    namespace: tacos

  # Sync policy for event-driven workload
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false

    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground
      - PruneLast=true
      - RespectIgnoreDifferences=true
      - ApplyOutOfSyncOnly=true

    retry:
      limit: 5
      backoff:
        duration: 10s
        factor: 2
        maxDuration: 5m0s

  revisionHistoryLimit: 10

  # Ignore KEDA and job-related status changes
  ignoreDifferences:
    # Ignore KEDA ScaledObject status
    - group: keda.sh
      kind: ScaledObject
      jsonPointers:
        - /status

    # Ignore Job replicas controlled by KEDA
    - group: batch
      kind: Job
      jsonPointers:
        - /status
        - /spec/parallelism

    # Ignore Deployment replicas scaled by KEDA
    - group: apps
      kind: Deployment
      jsonPointers:
        - /spec/replicas

  # Service information
  info:
    - name: Queue Name
      value: traffic-tacos-reservation-events
    - name: Scaling Type
      value: KEDA SQS Scaler (0-100 replicas)
    - name: Health Check
      value: http://reservation-worker.tacos.svc.cluster.local:8080/health
    - name: Metrics
      value: http://reservation-worker.tacos.svc.cluster.local:8080/metrics
    - name: Job Type
      value: Background Event Processing
    - name: Performance Dashboard
      value: https://grafana.traffictacos.com/d/reservation-worker/reservation-worker-dashboard

---
# KEDA ScaledObject for SQS-based auto-scaling
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: reservation-worker-scaledobject
  namespace: tacos
  labels:
    app.kubernetes.io/name: reservation-worker-scaler
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: autoscaling
  annotations:
    argocd.argoproj.io/sync-wave: "25"
spec:
  scaleTargetRef:
    name: reservation-worker

  # Scaling behavior
  pollingInterval: 30   # Check queue every 30 seconds
  cooldownPeriod: 300   # 5 minutes cooldown after scaling
  idleReplicaCount: 0   # Scale to zero when no messages
  minReplicaCount: 0
  maxReplicaCount: 100

  # Advanced scaling behavior
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 50  # Scale down 50% at a time
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 60
          policies:
          - type: Percent
            value: 100  # Double the pods when scaling up
            periodSeconds: 30
          - type: Pods
            value: 10   # Or add 10 pods, whichever is more conservative
            periodSeconds: 30

  # SQS Trigger
  triggers:
  - type: aws-sqs-queue
    metadata:
      queueURL: https://sqs.ap-northeast-2.amazonaws.com/ACCOUNT-ID/traffic-tacos-reservation-events
      queueLength: '5'  # 1 pod per 5 messages
      awsRegion: ap-northeast-2
      identityOwner: pod  # Use pod identity for AWS authentication

    authenticationRef:
      name: keda-aws-credentials

---
# TriggerAuthentication for AWS SQS
apiVersion: keda.sh/v1alpha1
kind: TriggerAuthentication
metadata:
  name: keda-aws-credentials
  namespace: tacos
  labels:
    app.kubernetes.io/name: keda-aws-auth
    app.kubernetes.io/part-of: traffic-tacos
  annotations:
    argocd.argoproj.io/sync-wave: "20"
spec:
  # Use Pod Identity for authentication
  podIdentity:
    provider: aws-eks  # EKS Pod Identity

---
# Enhanced Network Policy for Worker
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: reservation-worker-network-policy
  namespace: tacos
  labels:
    app.kubernetes.io/name: reservation-worker-network-policy
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: network-policy
  annotations:
    argocd.argoproj.io/sync-wave: "20"
spec:
  podSelector:
    matchLabels:
      app: reservation-worker

  policyTypes:
  - Ingress
  - Egress

  # Ingress rules (minimal for background worker)
  ingress:
    # Allow monitoring traffic
    - from:
      - namespaceSelector:
          matchLabels:
            name: monitoring
      ports:
      - protocol: TCP
        port: 8080  # Health and metrics

    # Allow communication from reservation-api
    - from:
      - podSelector:
          matchLabels:
            app: reservation-api
      ports:
      - protocol: TCP
        port: 8080

  # Egress rules for external dependencies
  egress:
    # DNS resolution
    - to: []
      ports:
      - protocol: UDP
        port: 53

    # HTTPS for AWS services (SQS, DynamoDB, EventBridge)
    - to: []
      ports:
      - protocol: TCP
        port: 443

    # Communication with reservation API for callbacks
    - to:
      - podSelector:
          matchLabels:
            app: reservation-api
      ports:
      - protocol: TCP
        port: 8080
      - protocol: TCP
        port: 8011  # gRPC

    # Communication with inventory API for seat management
    - to:
      - podSelector:
          matchLabels:
            app: inventory-api
      ports:
      - protocol: TCP
        port: 8020  # HTTP
      - protocol: TCP
        port: 8021  # gRPC

---
# ServiceMonitor for worker metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: reservation-worker-metrics
  namespace: tacos
  labels:
    app.kubernetes.io/name: reservation-worker-metrics
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: monitoring
  annotations:
    argocd.argoproj.io/sync-wave: "30"
spec:
  selector:
    matchLabels:
      app: reservation-worker
      monitoring: enabled

  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    scheme: http
    scrapeTimeout: 10s

  namespaceSelector:
    matchNames:
    - tacos

---
# Service Account with AWS IAM Role binding
apiVersion: v1
kind: ServiceAccount
metadata:
  name: reservation-worker
  namespace: tacos
  labels:
    app.kubernetes.io/name: reservation-worker-sa
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: identity
  annotations:
    argocd.argoproj.io/sync-wave: "15"
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT-ID:role/traffic-tacos-reservation-worker-role
automountServiceAccountToken: true

---
# ConfigMap for worker configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: reservation-worker-config
  namespace: tacos
  labels:
    app.kubernetes.io/name: reservation-worker-config
    app.kubernetes.io/part-of: traffic-tacos
    app.kubernetes.io/component: configuration
  annotations:
    argocd.argoproj.io/sync-wave: "15"
data:
  # Application configuration
  application.yaml: |
    server:
      port: 8080

    spring:
      application:
        name: reservation-worker

    # AWS configuration
    aws:
      region: ap-northeast-2
      sqs:
        queue-name: traffic-tacos-reservation-events
        max-number-of-messages: 10
        wait-time-seconds: 20
        visibility-timeout: 300

    # Job processing configuration
    worker:
      batch-size: 10
      max-retries: 3
      processing-timeout: 300
      error-handling-strategy: retry-with-backoff

    # Observability
    management:
      endpoints:
        web:
          exposure:
            include: health,metrics,prometheus
      metrics:
        export:
          prometheus:
            enabled: true

    # Logging
    logging:
      level:
        com.traffictacos: INFO
        root: INFO
      pattern:
        console: "%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

  # KEDA configuration
  keda.yaml: |
    triggers:
      - type: aws-sqs-queue
        metadata:
          queueURL: https://sqs.ap-northeast-2.amazonaws.com/ACCOUNT-ID/traffic-tacos-reservation-events
          queueLength: "5"
          awsRegion: ap-northeast-2