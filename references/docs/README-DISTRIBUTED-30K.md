# K6 Distributed Load Test - 30k RPS ğŸš€

## ğŸ“Š ê°œìš”

**30k RPS**ëŠ” ë§¤ìš° í° ë¶€í•˜ì´ë¯€ë¡œ **6ê°œì˜ ë³‘ë ¬ Job**ìœ¼ë¡œ ë¶„ì‚°í•˜ì—¬ ê°ê° 5k RPSì”© ì²˜ë¦¬í•©ë‹ˆë‹¤.

### ë¶€í•˜ ë¶„ì‚° ì „ëµ
- **Part 1-6**: ê°ê° 5k RPS
- **í•©ê³„**: 30k RPS (ëª©í‘œ RPS!)

### ë‹¨ê³„ë³„ ë¶€í•˜ íŒ¨í„´ (ì´ 26ë¶„)
```
0-3ë¶„:   0 â†’ 2k RPS (Warm-up)
3-8ë¶„:   2k â†’ 5k RPS (Ramp-up)
8-23ë¶„:  5k RPS ìœ ì§€ (Peak load - 15ë¶„ê°„!)
23-26ë¶„: 5k â†’ 0 RPS (Ramp-down)
```

**ê° Partê°€ ìœ„ íŒ¨í„´ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ì´ 30k RPS ë‹¬ì„±!**

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ì´ ë§¤ìš° í½ë‹ˆë‹¤!

#### ê° Job Pod
- **CPU**: 2 cores (request), 3 cores (limit)
- **Memory**: 4Gi (request), 6Gi (limit)
- **maxVUs**: 2500 VUs per job

#### ì „ì²´ (6 Jobs)
- **ì´ CPU**: **12 cores** (request), **18 cores** (limit)
- **ì´ Memory**: **24Gi** (request), **36Gi** (limit)
- **ì´ VUs**: ìµœëŒ€ **15,000 VUs**

#### í•„ìš” ë…¸ë“œ
- **ìµœì†Œ**: t3a.xlarge (4 cores, 16GB) Ã— 3-4ê°œ
- **ê¶Œì¥**: t3a.2xlarge (8 cores, 32GB) Ã— 2-3ê°œ
- **Karpenter**: loadtest nodepoolì— ì¶©ë¶„í•œ ë…¸ë“œ í™•ë³´ í•„ìš”

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 0. ì‚¬ì „ í™•ì¸ (í•„ìˆ˜!)

```bash
# loadtest ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes -l workload-type=loadtest -o wide

# í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top nodes -l workload-type=loadtest

# Karpenterê°€ ë…¸ë“œë¥¼ ì¶”ê°€ë¡œ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
kubectl get nodepools loadtest -o yaml | grep -A 5 limits

# âš ï¸ ë§Œì•½ ë…¸ë“œê°€ ë¶€ì¡±í•˜ë©´ Karpenterê°€ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì§€ë§Œ
# 6ê°œ íŒŒë“œë¥¼ ë™ì‹œì— ìŠ¤ì¼€ì¤„í•˜ë ¤ë©´ ì¶©ë¶„í•œ ìš©ëŸ‰ì´ í•„ìš”í•©ë‹ˆë‹¤!
```

### 1. ConfigMap ì ìš©
```bash
kubectl apply -f manifests/k6/job/k6-configmap-30k-distributed.yaml
```

**í™•ì¸:**
```bash
kubectl get cm -n load-test -l test=30k-distributed
# 6ê°œì˜ ConfigMapì´ ìƒì„±ë˜ì–´ì•¼ í•¨
```

### 2. Job ì‹¤í–‰ (ë³‘ë ¬ 6ê°œ)
```bash
kubectl apply -f manifests/k6/job/k6-job-parallel-30k.yaml
```

**í™•ì¸:**
```bash
# Job ìƒíƒœ
kubectl get jobs -n load-test -l test=30k-distributed

# Pod ìƒíƒœ
kubectl get pods -n load-test -l test=30k-distributed -o wide

# ëª¨ë“  íŒŒë“œê°€ Pendingì´ ì•„ë‹Œ Running ìƒíƒœì¸ì§€ í™•ì¸!
```

### 3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

#### íŒŒë“œ ìƒíƒœ Watch
```bash
watch -n 2 'kubectl get pods -n load-test -l test=30k-distributed -o wide'
```

#### ë¡œê·¸ í™•ì¸
```bash
# ëª¨ë“  Part ë¡œê·¸ ë™ì‹œì— ë³´ê¸°
kubectl logs -n load-test -l test=30k-distributed --all-containers=true -f

# íŠ¹ì • Partë§Œ ë³´ê¸°
kubectl logs -n load-test -l part=1 -f
```

#### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```bash
# ì‹¤ì‹œê°„ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
watch -n 5 'kubectl top pods -n load-test -l test=30k-distributed'

# ë…¸ë“œ ë¦¬ì†ŒìŠ¤
watch -n 5 'kubectl top nodes -l workload-type=loadtest'
```

## ğŸ“ˆ ê²°ê³¼ í™•ì¸

### Grafana Dashboard

**Prometheus ì¿¼ë¦¬:**

```promql
# ì „ì²´ RPS (30k ëª©í‘œ)
sum(rate(http_reqs_total{test="30k"}[1m]))

# Partë³„ RPS (ê° 5k ëª©í‘œ)
sum(rate(http_reqs_total{test="30k",part="1"}[1m]))
sum(rate(http_reqs_total{test="30k",part="2"}[1m]))
sum(rate(http_reqs_total{test="30k",part="3"}[1m]))
sum(rate(http_reqs_total{test="30k",part="4"}[1m]))
sum(rate(http_reqs_total{test="30k",part="5"}[1m]))
sum(rate(http_reqs_total{test="30k",part="6"}[1m]))

# P95 Latency
histogram_quantile(0.95, sum(rate(http_req_duration_bucket{test="30k"}[1m])) by (le))

# P99 Latency
histogram_quantile(0.99, sum(rate(http_req_duration_bucket{test="30k"}[1m])) by (le))

# ì‹¤íŒ¨ìœ¨
rate(http_req_failed_total{test="30k"}[1m]) / rate(http_reqs_total{test="30k"}[1m])

# ì™„ë£Œëœ í”Œë¡œìš°
sum(rate(completed_flows_total{test="30k"}[1m]))
```

### ì˜ˆìƒ ê²°ê³¼

**ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤:**
- âœ… ì „ì²´ RPS: 28k-30k (ëª©í‘œ ë‹¬ì„±!)
- âœ… P95 Latency: < 5ì´ˆ
- âœ… P99 Latency: < 8ì´ˆ
- âœ… ì‹¤íŒ¨ìœ¨: < 15%

**ë¶€ë¶„ ì„±ê³µ:**
- âš ï¸ ì „ì²´ RPS: 20k-28k (ë¶€í•˜ ë¶„ì‚° íš¨ê³¼ëŠ” ìˆìŒ)
- âš ï¸ ì¼ë¶€ Pod OOMKilled (ë©”ëª¨ë¦¬ ì¦ê°€ í•„ìš”)

**ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤:**
- âŒ Pod ëŒ€ë¶€ë¶„ Pending (ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±)
- âŒ Pod OOMKilled ë°˜ë³µ (ë©”ëª¨ë¦¬ í•œê³„)
- âŒ P99 Latency > 10ì´ˆ (ë°±ì—”ë“œ ë³‘ëª©)

## ğŸ§¹ ì •ë¦¬

### ì‹¤í–‰ ì¤‘ì¸ Job í™•ì¸
```bash
kubectl get jobs -n load-test -l test=30k-distributed
```

### Job ì‚­ì œ
```bash
kubectl delete job -n load-test -l test=30k-distributed
```

### ConfigMap ì‚­ì œ
```bash
kubectl delete cm -n load-test -l test=30k-distributed
```

### í•œ ë²ˆì— ì „ì²´ ì‚­ì œ
```bash
kubectl delete -f manifests/k6/job/k6-job-parallel-30k.yaml
kubectl delete -f manifests/k6/job/k6-configmap-30k-distributed.yaml
```

## ğŸ”§ Troubleshooting

### 1. Podê°€ Pending ìƒíƒœë¡œ ë©ˆì¶¤

**ì›ì¸:** ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

**í•´ê²°:**
```bash
# Karpenterê°€ ë…¸ë“œë¥¼ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸
kubectl get nodeclaims -l karpenter.sh/nodepool=loadtest

# ìˆ˜ë™ìœ¼ë¡œ NodePool ìŠ¤ì¼€ì¼ í™•ì¸
kubectl describe nodepool loadtest

# ì„ì‹œ í•´ê²°: ì¼ë¶€ Jobë§Œ ì‹¤í–‰
kubectl apply -f manifests/k6/job/k6-job-parallel-30k.yaml
# ê·¸ëŸ° ë‹¤ìŒ ì¼ë¶€ Job ì‚­ì œ
kubectl delete job k6-loadtest-30k-part5 k6-loadtest-30k-part6 -n load-test
```

### 2. Podê°€ OOMKilled

**ì›ì¸:** ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°:** Job YAMLì—ì„œ ë©”ëª¨ë¦¬ ì¦ê°€
```yaml
resources:
  requests:
    memory: "6Gi"  # 4Gi â†’ 6Gi
  limits:
    memory: "8Gi"  # 6Gi â†’ 8Gi
```

### 3. RPSê°€ ëª©í‘œì— í¬ê²Œ ëª» ë¯¸ì¹¨

**ì›ì¸:** 
- ë°±ì—”ë“œ ë³‘ëª©
- K6 íŒŒë“œ CPU ì œí•œ
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ë¶€ì¡±

**í™•ì¸:**
```bash
# K6 íŒŒë“œ CPU ì‚¬ìš©ë¥ 
kubectl top pods -n load-test -l test=30k-distributed

# ë°±ì—”ë“œ API íŒŒë“œ ìƒíƒœ
kubectl get pods -n tacos-app -l app=gateway-api
kubectl top pods -n tacos-app -l app=gateway-api
```

**í•´ê²°:**
- CPU limit ì¦ê°€
- maxVUs ì¦ê°€
- ë°±ì—”ë“œ ìŠ¤ì¼€ì¼ ì•„ì›ƒ

### 4. ì¼ë¶€ Partë§Œ ì‹¤í–‰ë˜ê³  ë‚˜ë¨¸ì§€ëŠ” Pending

**ì›ì¸:** ìˆœì°¨ì  ìŠ¤ì¼€ì¤„ë§

**ëŒ€ê¸°:** Karpenterê°€ ë…¸ë“œë¥¼ ì¶”ê°€ë¡œ ìƒì„±í•  ë•Œê¹Œì§€ 2-5ë¶„ ëŒ€ê¸°

**í™•ì¸:**
```bash
# ìƒˆ ë…¸ë“œê°€ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
watch -n 5 'kubectl get nodes -l workload-type=loadtest'
```

## ğŸ“Š ë¹„êµ: 10k vs 30k

| í•­ëª© | 10k RPS | 30k RPS |
|---|---|---|
| **íŒŒë“œ ìˆ˜** | 3ê°œ | 6ê°œ |
| **íŒŒë“œë‹¹ ë¶€í•˜** | 3.3k RPS | 5k RPS |
| **ì´ CPU** | 4.5-6 cores | 12-18 cores |
| **ì´ Memory** | 9-12Gi | 24-36Gi |
| **maxVUs** | 4,500 | 15,000 |
| **í…ŒìŠ¤íŠ¸ ì‹œê°„** | 20ë¶„ | 26ë¶„ |
| **í•„ìš” ë…¸ë“œ** | 2-3ê°œ | 4-6ê°œ |

## ğŸ¯ ì„±ê³µ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ ì „ í™•ì¸:
- [ ] loadtest ë…¸ë“œ ìµœì†Œ 3ê°œ ì´ìƒ
- [ ] ì´ CPU ì—¬ìœ : 18 cores ì´ìƒ
- [ ] ì´ Memory ì—¬ìœ : 40Gi ì´ìƒ
- [ ] Karpenter nodepool ì •ìƒ ì‘ë™
- [ ] ë°±ì—”ë“œ API ì •ìƒ ìƒíƒœ

ì‹¤í–‰ ì¤‘ ëª¨ë‹ˆí„°ë§:
- [ ] 6ê°œ íŒŒë“œ ëª¨ë‘ Running ìƒíƒœ
- [ ] OOMKilled ì—†ìŒ
- [ ] ê° Partê°€ 5k RPS ë‹¬ì„±
- [ ] P95 Latency < 5ì´ˆ
- [ ] ì‹¤íŒ¨ìœ¨ < 15%

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

### 30k ì„±ê³µ í›„

1. **ê²°ê³¼ ë¶„ì„**
   - Grafana ëŒ€ì‹œë³´ë“œ ìŠ¤í¬ë¦°ìƒ·
   - ë³‘ëª© êµ¬ê°„ ì‹ë³„
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŒ¨í„´ ë¶„ì„

2. **ìµœì í™”**
   - ë°±ì—”ë“œ API HPA íŠœë‹
   - Database connection pool ì¡°ì •
   - Redis ìºì‹œ íˆíŠ¸ìœ¨ ê°œì„ 

3. **K6 Operatorë¡œ ì „í™˜**
   - ë” ì‰¬ìš´ ê´€ë¦¬
   - ìë™ ë¶€í•˜ ë¶„ì‚°
   - í†µí•©ëœ ê²°ê³¼ ìˆ˜ì§‘

### 50k RPS ë„ì „?

30kê°€ ì•ˆì •ì ì´ë©´:
- 10ê°œ íŒŒë“œë¡œ í™•ì¥ (ê° 5k RPS)
- ë˜ëŠ” 6ê°œ íŒŒë“œ + ê° 8-9k RPS

## ğŸ“ ì°¸ê³ 

- **10k í…ŒìŠ¤íŠ¸**: `README-DISTRIBUTED-10K.md`
- **K6 ê³µì‹ ë¬¸ì„œ**: https://k6.io/docs/
- **K6 Operator**: https://github.com/grafana/k6-operator

---

**Good luck with 30k RPS! ğŸ‰**
